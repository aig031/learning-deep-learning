Ultimate dream: thinking machine

-> 뇌를 연구했더니, 수도 없이 많은 '뉴런'(상상이로 간단함)으로 이루어져 있다.

Activation Functions(뉴런을 구현해보자) -> 기계가 특정 input에 대해서 특정 output을 나오게 하자.

(Simple)AND/OR problem: linearly separable? -> 를 자동으로 구분하게 할 수 있을까?: 할 수 있다.
-> (Simple)XOR problem: linearly separable? : 할 수 없다.

Perceptrons : linear is impossible -> MLP(multilayer perceptrons,여러개의 machine을 이용하자.)
             -> 각각의 machine을 학습할 수 없기 때문에 불가능하다.

Backpropogation(해결!) : 앞으로 진행한 결과 값에 error가 있었다면, 다시 뒤로 하나씩 돌아가서 w1b를 재 학습.
           
Convolutional Neural Networks : 그림을 작게 나누어, 각자 학습 시킨 뒤, 이를 합친다.
	-> 글, 그림을 구분하는 것에서 나아가 자동 주행 자동차 등으로 발전.

A BIG problem: Backpropagation이 많은 layer를 가지고 있는데 뒤로 가면 갈수록 error 값의 정보가 제대로 전달되지 않아 학습이 제대로 이루어지지 않을 수 있다.
-> SVM, RandomForest, etc. 같은 다른 machine algorithm이 대두되었다.
